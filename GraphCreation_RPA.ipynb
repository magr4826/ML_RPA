{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymatgen.entries.computed_entries import ComputedStructureEntry\n",
    "import pickle\n",
    "from torch_geometric.data import Data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"database\")\n",
    "all_files = os.listdir()\n",
    "\n",
    "\n",
    "data = []\n",
    "missing = []\n",
    "for filename in sorted(all_files):\n",
    "    if \".json\" in filename:\n",
    "        with open(filename, \"r\") as file:\n",
    "            try:\n",
    "                entry = json.load(file)\n",
    "            except:\n",
    "                print(filename)\n",
    "                continue\n",
    "\n",
    "            cse = ComputedStructureEntry.from_dict(entry)\n",
    "            if \"rpa_similarity\" in cse.data:\n",
    "                data.append({\"structure\": cse.structure}\n",
    "                            | cse.data | cse.parameters)\n",
    "            elif cse.data[\"nsites\"] <= 8:\n",
    "                missing.append(cse.data[\"mat_id\"])\n",
    "            else:\n",
    "                continue\n",
    "data_df = pd.DataFrame(data)\n",
    "os.chdir(os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop materials which are close to being metals\n",
    "data_df = data_df.drop(data_df[data_df[\"ipa_indirect_gap\"] < 0.5].index)\n",
    "# drop materials whose gap is too large to yield reasonable information\n",
    "data_df = data_df.drop(data_df[data_df[\"ipa_direct_gap\"] > 10].index)\n",
    "\n",
    "data_df = data_df.drop(\n",
    "    data_df[data_df.mat_id == \"agm005546161\"].index\n",
    ")  # very rare YAMBO error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process spectral data\n",
    "rpa_epsI_xx = []\n",
    "rpa_epsI_yy = []\n",
    "rpa_epsI_zz = []\n",
    "ipa_epsI_xx = []\n",
    "ipa_epsI_yy = []\n",
    "ipa_epsI_zz = []\n",
    "for idr, entry in data_df.iterrows():\n",
    "    if type(entry[\"rpa_epsI\"]) == float:\n",
    "        rpa_epsI_xx.append(np.nan)\n",
    "        rpa_epsI_yy.append(np.nan)\n",
    "        rpa_epsI_zz.append(np.nan)\n",
    "        ipa_epsI_xx.append(np.nan)\n",
    "        ipa_epsI_yy.append(np.nan)\n",
    "        ipa_epsI_zz.append(np.nan)\n",
    "        continue\n",
    "    rpa_epsI_xx.append(entry[\"rpa_epsI\"][\"xx\"])\n",
    "    ipa_epsI_xx.append(entry[\"ipa_epsI\"][\"xx\"])\n",
    "    if \"yy\" in entry[\"rpa_epsI\"].keys():\n",
    "        rpa_epsI_yy.append(entry[\"rpa_epsI\"][\"yy\"])\n",
    "        ipa_epsI_yy.append(entry[\"ipa_epsI\"][\"yy\"])\n",
    "    else:\n",
    "        rpa_epsI_yy.append(entry[\"rpa_epsI\"][\"xx\"])\n",
    "        ipa_epsI_yy.append(entry[\"ipa_epsI\"][\"xx\"])\n",
    "    if \"zz\" in entry[\"rpa_epsI\"].keys():\n",
    "        rpa_epsI_zz.append(entry[\"rpa_epsI\"][\"zz\"])\n",
    "        ipa_epsI_zz.append(entry[\"ipa_epsI\"][\"zz\"])\n",
    "    else:\n",
    "        rpa_epsI_zz.append(entry[\"rpa_epsI\"][\"xx\"])\n",
    "        ipa_epsI_zz.append(entry[\"ipa_epsI\"][\"xx\"])\n",
    "data_df[\"rpa_epsI_xx\"] = rpa_epsI_xx\n",
    "data_df[\"rpa_epsI_yy\"] = rpa_epsI_yy\n",
    "data_df[\"rpa_epsI_zz\"] = rpa_epsI_zz\n",
    "data_df[\"ipa_epsI_xx\"] = ipa_epsI_xx\n",
    "data_df[\"ipa_epsI_yy\"] = ipa_epsI_yy\n",
    "data_df[\"ipa_epsI_zz\"] = ipa_epsI_zz\n",
    "\n",
    "rpa_epsR_xx = []\n",
    "rpa_epsR_yy = []\n",
    "rpa_epsR_zz = []\n",
    "ipa_epsR_xx = []\n",
    "ipa_epsR_yy = []\n",
    "ipa_epsR_zz = []\n",
    "for idr, entry in data_df.iterrows():\n",
    "    if type(entry[\"rpa_epsI\"]) == float:\n",
    "        rpa_epsR_xx.append(np.nan)\n",
    "        rpa_epsR_yy.append(np.nan)\n",
    "        rpa_epsR_zz.append(np.nan)\n",
    "        ipa_epsR_xx.append(np.nan)\n",
    "        ipa_epsR_yy.append(np.nan)\n",
    "        ipa_epsR_zz.append(np.nan)\n",
    "        continue\n",
    "    rpa_epsR_xx.append(entry[\"rpa_epsR\"][\"xx\"])\n",
    "    ipa_epsR_xx.append(entry[\"ipa_epsR\"][\"xx\"])\n",
    "    if \"yy\" in entry[\"rpa_epsR\"].keys():\n",
    "        rpa_epsR_yy.append(entry[\"rpa_epsR\"][\"yy\"])\n",
    "        ipa_epsR_yy.append(entry[\"ipa_epsR\"][\"yy\"])\n",
    "    else:\n",
    "        rpa_epsR_yy.append(entry[\"rpa_epsR\"][\"xx\"])\n",
    "        ipa_epsR_yy.append(entry[\"ipa_epsR\"][\"xx\"])\n",
    "    if \"zz\" in entry[\"rpa_epsR\"].keys():\n",
    "        rpa_epsR_zz.append(entry[\"rpa_epsR\"][\"zz\"])\n",
    "        ipa_epsR_zz.append(entry[\"ipa_epsR\"][\"zz\"])\n",
    "    else:\n",
    "        rpa_epsR_zz.append(entry[\"rpa_epsR\"][\"xx\"])\n",
    "        ipa_epsR_zz.append(entry[\"ipa_epsR\"][\"xx\"])\n",
    "data_df[\"rpa_epsR_xx\"] = rpa_epsR_xx\n",
    "data_df[\"rpa_epsR_yy\"] = rpa_epsR_yy\n",
    "data_df[\"rpa_epsR_zz\"] = rpa_epsR_zz\n",
    "data_df[\"ipa_epsR_xx\"] = ipa_epsR_xx\n",
    "data_df[\"ipa_epsR_yy\"] = ipa_epsR_yy\n",
    "data_df[\"ipa_epsR_zz\"] = ipa_epsR_zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"database/data_300_rpa.pckl\", \"wb+\") as file:\n",
    "    pickle.dump(data_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graphs from preset cutoff length and gaussian expanded edges (target = RPA)\n",
    "graphs = []\n",
    "for data_idx, entry in data_df.iterrows():\n",
    "    if data_idx % 100 == 0:\n",
    "        print(data_idx)\n",
    "    if type(entry[\"rpa_epsI_xx\"]) == float:\n",
    "        continue\n",
    "    structure = entry[\"structure\"]\n",
    "    gap = entry[\"ipa_direct_gap\"]\n",
    "    epsi0 = entry[\"rpa_epsI_xx\"]\n",
    "    epsi1 = entry[\"rpa_epsI_yy\"]\n",
    "    epsi2 = entry[\"rpa_epsI_zz\"]\n",
    "    epsr0 = entry[\"rpa_epsR_xx\"]\n",
    "    epsr1 = entry[\"rpa_epsR_yy\"]\n",
    "    epsr2 = entry[\"rpa_epsR_zz\"]\n",
    "\n",
    "    epsi0_ipa = entry[\"ipa_epsI_xx\"]\n",
    "    epsi1_ipa = entry[\"ipa_epsI_yy\"]\n",
    "    epsi2_ipa = entry[\"ipa_epsI_zz\"]\n",
    "    epsr0_ipa = entry[\"ipa_epsR_xx\"]\n",
    "    epsr1_ipa = entry[\"ipa_epsR_yy\"]\n",
    "    epsr2_ipa = entry[\"ipa_epsR_zz\"]\n",
    "\n",
    "    epsr = 1 / 3 * (epsr0 + epsr1 + epsr2)\n",
    "    epsi = 1 / 3 * (epsi0 + epsi1 + epsi2)\n",
    "    epsr_ipa = 1 / 3 * (epsr0_ipa + epsr1_ipa + epsr2_ipa)\n",
    "    epsi_ipa = 1 / 3 * (epsi0_ipa + epsi1_ipa + epsi2_ipa)\n",
    "    nbr_fea_idx = []\n",
    "    nbr_fea = []\n",
    "\n",
    "    self_fea_idx = []\n",
    "\n",
    "    all_nbrs = structure.get_all_neighbors(5)\n",
    "    for site, nbr in enumerate(all_nbrs):\n",
    "        nbr_fea_idx_sub, nbr_fea_sub, self_fea_idx_sub = [], [], []\n",
    "\n",
    "        for n in range(len(nbr)):\n",
    "            self_fea_idx_sub.append(site)\n",
    "\n",
    "        for j in range(len(nbr)):\n",
    "            nbr_fea_idx_sub.append(nbr[j][2])\n",
    "\n",
    "        for j in range(len(nbr)):\n",
    "            nbr_fea_sub.append(nbr[j][1])\n",
    "\n",
    "        nbr_fea_idx.append(nbr_fea_idx_sub)\n",
    "        nbr_fea.append(nbr_fea_sub)\n",
    "\n",
    "        self_fea_idx.append(self_fea_idx_sub)\n",
    "\n",
    "    edges = torch.stack(\n",
    "        (\n",
    "            torch.tensor(\n",
    "                [item for items in self_fea_idx for item in items], dtype=torch.long\n",
    "            ),\n",
    "            torch.tensor(\n",
    "                [item for items in nbr_fea_idx for item in items], dtype=torch.long\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "    nbr_fea = [item for items in nbr_fea for item in items]\n",
    "    x_vals = np.linspace(0, 5, 51)\n",
    "    edge_attr = np.sqrt(10 / np.pi) * np.array(\n",
    "        [np.exp(-10 * (nbr_fea - val) ** 2) for val in x_vals]\n",
    "    )\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "    edge_attr = torch.transpose(edge_attr, 0, 1)\n",
    "\n",
    "    atoms = np.array(range(len(all_nbrs)))\n",
    "    self_fea = []\n",
    "\n",
    "    for atom_id in atoms:\n",
    "        # encode atom information by group and row\n",
    "        group = torch.tensor(\n",
    "            structure.species[atom_id].group - 1, dtype=torch.int64)\n",
    "        if group > 1:\n",
    "            group -= 10\n",
    "        row = torch.tensor(\n",
    "            structure.species[atom_id].row - 1, dtype=torch.int64)\n",
    "        group = torch.nn.functional.one_hot(group, num_classes=8)\n",
    "        row = torch.nn.functional.one_hot(row, num_classes=5)\n",
    "        self_fea.append(torch.hstack([group, row]))\n",
    "\n",
    "    self_fea = torch.vstack(self_fea)\n",
    "    nbr_fea = torch.tensor(nbr_fea, dtype=torch.float)\n",
    "    edge_attr = edge_attr\n",
    "\n",
    "    try:\n",
    "        graph = Data(\n",
    "            x=self_fea.to(torch.float32),\n",
    "            edge_index=edges,\n",
    "            edge_attr=edge_attr,\n",
    "            y=torch.tensor(epsi, dtype=torch.float),\n",
    "            ipa=torch.tensor(epsi_ipa, dtype=torch.float),\n",
    "        )\n",
    "    except:\n",
    "        print(entry[\"mat_id\"])\n",
    "        continue\n",
    "\n",
    "    graph[\"mat_id\"] = entry[\"mat_id\"]\n",
    "    graphs.append(graph)\n",
    "\n",
    "with open(\"database/graphs_300_rpa.pckl\", \"wb+\") as file:\n",
    "    pickle.dump(graphs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
