{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as L\n",
    "import torch_geometric\n",
    "import torch\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import re\n",
    "\n",
    "import src.utils as utils\n",
    "import src.models as models\n",
    "\n",
    "seed = 0\n",
    "\n",
    "\n",
    "def get_sc(X, Y):\n",
    "    X = np.stack(X.values)\n",
    "    Y = np.stack(Y.values)\n",
    "    return 1 - np.trapz(np.abs(X - Y), axis=1) / np.trapz(abs(Y), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"database/graphs_300_rpa.pckl\", \"rb\") as graph_file:\n",
    "    graphs = pickle.load(graph_file)\n",
    "data_df = pd.read_pickle(\"database/data_300_rpa.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = utils.train_val_test(graphs)\n",
    "random.seed(seed)\n",
    "\n",
    "# select here on how many samples you want to train\n",
    "curr_train = random.sample(train, 300)\n",
    "\n",
    "# optimal parameters\n",
    "params_100 = [[96, 96, 96], [192, 2], [512, 512, 512]]\n",
    "params_300 = [[96, 96, 96], [384, 4], [512, 512]]\n",
    "params_1000 = [[96, 96, 96], [192, 8], [96, 8], [96, 2], [2048, 2048, 2048]]\n",
    "params_3000 = [[48, 48, 48], [384, 8], [2048, 2048, 2048]]\n",
    "params_4610 = [[96, 96], [192, 8], [192, 2], [2048, 2048, 2048]]\n",
    "params_ipa = [[48, 48], [48, 4], [96, 4], [1024, 1024, 1024]]\n",
    "\n",
    "print(\"Length of full training set: \" + str(len(train)))\n",
    "print(\"Length of full validation set: \" + str(len(val)))\n",
    "print(\"Length of full test set: \" + str(len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train various models\n",
    "\n",
    "These cells do not need to be run as trained models are supplied already.         \n",
    "The line which saves the state_dict is also commented out for that reason.            \n",
    "If you want to train your own models, check for optimal hyperparameters in the Supplemental Information of the paper.            \n",
    "If you use these, you should get similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a TL model\n",
    "checkpoint_callback = L.callbacks.ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "    monitor=\"valid\",\n",
    "    mode=\"min\",\n",
    "    dirpath=\"ckpts\",\n",
    "    filename=\"{epoch:02d}-{valid:.2f}\",\n",
    ")\n",
    "\n",
    "TrainLoader = torch_geometric.loader.DataLoader(\n",
    "    curr_train, batch_size=128, shuffle=True\n",
    ")\n",
    "ValLoader = torch_geometric.loader.DataLoader(val, batch_size=128, shuffle=False)\n",
    "TestLoader = torch_geometric.loader.DataLoader(test, batch_size=1, shuffle=False)\n",
    "\n",
    "model_tl = models.LitGatNN_pre(\"IPA_results/eps_300.pt\", lr=1e-5, decay=1e-4)\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=500,\n",
    "    check_val_every_n_epoch=20,\n",
    "    precision=\"bf16-mixed\",\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "trainer.fit(model=model_tl, train_dataloaders=TrainLoader, val_dataloaders=ValLoader)\n",
    "checkpoint = torch.load(checkpoint_callback.best_model_path)\n",
    "model_tl.load_state_dict(checkpoint[\"state_dict\"])\n",
    "results = utils.model_eval(model_tl, TestLoader, data_df)\n",
    "results.describe()\n",
    "# torch.save(model_tl.state_dict(), \"trained_models/tl4610.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a DL model\n",
    "\n",
    "TrainLoader = torch_geometric.loader.DataLoader(\n",
    "    curr_train, batch_size=20, shuffle=True, drop_last=True\n",
    ")\n",
    "ValLoader = torch_geometric.loader.DataLoader(val, batch_size=32, shuffle=False)\n",
    "TestLoader = torch_geometric.loader.DataLoader(test, batch_size=1, shuffle=False)\n",
    "\n",
    "checkpoint_callback = L.callbacks.ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "    monitor=\"valid\",\n",
    "    mode=\"min\",\n",
    "    dirpath=\"ckpts\",\n",
    "    filename=\"{epoch:02d}-{valid:.2f}\",\n",
    ")\n",
    "\n",
    "model_dl = models.LitGatNN(lr=1e-5, decay=1e-4, params=params_300)\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=500,\n",
    "    check_val_every_n_epoch=20,\n",
    "    precision=\"bf16-mixed\",\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "trainer.fit(model=model_dl, train_dataloaders=TrainLoader, val_dataloaders=ValLoader)\n",
    "checkpoint = torch.load(checkpoint_callback.best_model_path)\n",
    "model_dl.load_state_dict(checkpoint[\"state_dict\"])\n",
    "results = utils.model_eval(model_dl, TestLoader, data_df)\n",
    "results.describe()\n",
    "# torch.save(model_dl.state_dict(), \"trained_models/dl300.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TL on small cells\n",
    "\n",
    "for max_size in range(2, 7):\n",
    "    # select only small cells\n",
    "    small_train = []\n",
    "    max_sites = max_size\n",
    "    for graph in train:\n",
    "        if graph.x.shape[0] <= max_sites:\n",
    "            small_train.append(graph)\n",
    "\n",
    "    # Train a TL model\n",
    "    checkpoint_callback = L.callbacks.ModelCheckpoint(\n",
    "        save_top_k=1,\n",
    "        monitor=\"valid\",\n",
    "        mode=\"min\",\n",
    "        dirpath=\"ckpts\",\n",
    "        filename=\"{epoch:02d}-{valid:.2f}\",\n",
    "    )\n",
    "\n",
    "    TrainLoader = torch_geometric.loader.DataLoader(\n",
    "        small_train, batch_size=128, shuffle=True\n",
    "    )\n",
    "    ValLoader = torch_geometric.loader.DataLoader(val, batch_size=128, shuffle=False)\n",
    "    TestLoader = torch_geometric.loader.DataLoader(test, batch_size=1, shuffle=False)\n",
    "\n",
    "    model_tl = models.LitGatNN_pre(\"IPA_results/eps_300.pt\", lr=1e-5, decay=1e-4)\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=500,\n",
    "        check_val_every_n_epoch=20,\n",
    "        precision=\"bf16-mixed\",\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "    trainer.fit(\n",
    "        model=model_tl, train_dataloaders=TrainLoader, val_dataloaders=ValLoader\n",
    "    )\n",
    "    checkpoint = torch.load(checkpoint_callback.best_model_path)\n",
    "    model_tl.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    results = utils.model_eval(model_tl, TestLoader, data_df)\n",
    "    results.describe()\n",
    "    # torch.save(model_tl.state_dict(), f\"trained_models/tl{max_size}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an IPA model\n",
    "model_ipa = models.LitGatNN_pre(\"IPA_results/eps_300.pt\", lr=2e-3, decay=0)\n",
    "model_ipa.eval()\n",
    "model_ipa.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DL models\n",
    "model_dl_100 = models.LitGatNN(lr=1e-3, decay=0, params=params_100)\n",
    "state_dict = torch.load(\"trained_models/dl100.pt\")\n",
    "model_dl_100.load_state_dict(state_dict)\n",
    "model_dl_300 = models.LitGatNN(lr=1e-3, decay=0, params=params_300)\n",
    "state_dict = torch.load(\"trained_models/dl300.pt\")\n",
    "model_dl_300.load_state_dict(state_dict)\n",
    "model_dl_1000 = models.LitGatNN(lr=1e-3, decay=0, params=params_1000)\n",
    "state_dict = torch.load(\"trained_models/dl1000.pt\")\n",
    "model_dl_1000.load_state_dict(state_dict)\n",
    "model_dl_3000 = models.LitGatNN(lr=1e-3, decay=0, params=params_3000)\n",
    "state_dict = torch.load(\"trained_models/dl3000.pt\")\n",
    "model_dl_3000.load_state_dict(state_dict)\n",
    "model_dl_4610 = models.LitGatNN(lr=1e-3, decay=0, params=params_4610)\n",
    "state_dict = torch.load(\"trained_models/dl4610.pt\")\n",
    "model_dl_4610.load_state_dict(state_dict)\n",
    "\n",
    "model_dl_100.cuda()\n",
    "model_dl_300.cuda()\n",
    "model_dl_1000.cuda()\n",
    "model_dl_3000.cuda()\n",
    "model_dl_4610.cuda()\n",
    "\n",
    "model_dl_100.eval()\n",
    "model_dl_300.eval()\n",
    "model_dl_1000.eval()\n",
    "model_dl_3000.eval()\n",
    "model_dl_4610.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TL models\n",
    "model_tl_100 = models.LitGatNN_pre(\"IPA_results/eps_300.pt\", lr=1e-5, decay=1e-4)\n",
    "state_dict = torch.load(\"trained_models/tl100.pt\")\n",
    "model_tl_100.load_state_dict(state_dict)\n",
    "model_tl_300 = models.LitGatNN_pre(\"IPA_results/eps_300.pt\", lr=1e-5, decay=1e-4)\n",
    "state_dict = torch.load(\"trained_models/tl300.pt\")\n",
    "model_tl_300.load_state_dict(state_dict)\n",
    "model_tl_1000 = models.LitGatNN_pre(\"IPA_results/eps_300.pt\", lr=1e-5, decay=1e-4)\n",
    "state_dict = torch.load(\"trained_models/tl1000.pt\")\n",
    "model_tl_1000.load_state_dict(state_dict)\n",
    "model_tl_3000 = models.LitGatNN_pre(\"IPA_results/eps_300.pt\", lr=1e-5, decay=1e-4)\n",
    "state_dict = torch.load(\"trained_models/tl3000.pt\")\n",
    "model_tl_3000.load_state_dict(state_dict)\n",
    "model_tl_4610 = models.LitGatNN_pre(\"IPA_results/eps_300.pt\", lr=1e-5, decay=1e-4)\n",
    "state_dict = torch.load(\"trained_models/tl4610.pt\")\n",
    "model_tl_4610.load_state_dict(state_dict)\n",
    "\n",
    "model_tl_100.cuda()\n",
    "model_tl_300.cuda()\n",
    "model_tl_1000.cuda()\n",
    "model_tl_3000.cuda()\n",
    "model_tl_4610.cuda()\n",
    "\n",
    "model_tl_100.eval()\n",
    "model_tl_300.eval()\n",
    "model_tl_1000.eval()\n",
    "model_tl_3000.eval()\n",
    "model_tl_4610.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load small models\n",
    "model_tl_2 = models.LitGatNN_pre(\"IPA_results/eps_300.pt\", lr=1e-5, decay=1e-4)\n",
    "state_dict = torch.load(\"trained_models/tl2.pt\")\n",
    "model_tl_2.load_state_dict(state_dict)\n",
    "model_tl_3 = models.LitGatNN_pre(\"IPA_results/eps_300.pt\", lr=1e-5, decay=1e-4)\n",
    "state_dict = torch.load(\"trained_models/tl3.pt\")\n",
    "model_tl_3.load_state_dict(state_dict)\n",
    "model_tl_4 = models.LitGatNN_pre(\"IPA_results/eps_300.pt\", lr=1e-5, decay=1e-4)\n",
    "state_dict = torch.load(\"trained_models/tl4.pt\")\n",
    "model_tl_4.load_state_dict(state_dict)\n",
    "model_tl_5 = models.LitGatNN_pre(\"IPA_results/eps_300.pt\", lr=1e-5, decay=1e-4)\n",
    "state_dict = torch.load(\"trained_models/tl5.pt\")\n",
    "model_tl_5.load_state_dict(state_dict)\n",
    "model_tl_6 = models.LitGatNN_pre(\"IPA_results/eps_300.pt\", lr=1e-5, decay=1e-4)\n",
    "state_dict = torch.load(\"trained_models/tl6.pt\")\n",
    "model_tl_6.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "model_tl_2.cuda()\n",
    "model_tl_3.cuda()\n",
    "model_tl_4.cuda()\n",
    "model_tl_5.cuda()\n",
    "model_tl_6.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in test:\n",
    "    graph.cuda()\n",
    "TestLoader = torch_geometric.loader.DataLoader(test, batch_size=1, shuffle=False)\n",
    "results_dl_100 = utils.model_eval(model_dl_100, TestLoader, data_df)\n",
    "results_dl_300 = utils.model_eval(model_dl_300, TestLoader, data_df)\n",
    "results_dl_1000 = utils.model_eval(model_dl_1000, TestLoader, data_df)\n",
    "results_dl_3000 = utils.model_eval(model_dl_3000, TestLoader, data_df)\n",
    "results_dl_4610 = utils.model_eval(model_dl_4610, TestLoader, data_df)\n",
    "\n",
    "results_tl_100 = utils.model_eval(model_tl_100, TestLoader, data_df)\n",
    "results_tl_300 = utils.model_eval(model_tl_300, TestLoader, data_df)\n",
    "results_tl_1000 = utils.model_eval(model_tl_1000, TestLoader, data_df)\n",
    "results_tl_3000 = utils.model_eval(model_tl_3000, TestLoader, data_df)\n",
    "results_tl_4610 = utils.model_eval(model_tl_4610, TestLoader, data_df)\n",
    "\n",
    "results_tl_2 = utils.model_eval(model_tl_2, TestLoader, data_df)\n",
    "results_tl_3 = utils.model_eval(model_tl_3, TestLoader, data_df)\n",
    "results_tl_4 = utils.model_eval(model_tl_4, TestLoader, data_df)\n",
    "results_tl_5 = utils.model_eval(model_tl_5, TestLoader, data_df)\n",
    "results_tl_6 = utils.model_eval(model_tl_6, TestLoader, data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One can get the error measures on the test set like so:\n",
    "results_dl_100.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model trained on small cells for separate cell sizes\n",
    "errors_and_size = []\n",
    "for _, row in results_tl_4.iterrows():\n",
    "    n_sites = data_df[data_df[\"mat_id\"] == row[\"name\"][0]].nsites.values[0]\n",
    "    errors_and_size.append([row.mse, row.sc, n_sites])\n",
    "\n",
    "list_of_lists = [[], [], [], [], [], [], [], []]\n",
    "for row in errors_and_size:\n",
    "    list_of_lists[row[2] - 1].append([row[0], row[1]])\n",
    "for idx, row in enumerate(list_of_lists):\n",
    "    list_of_lists[idx] = np.array(row)\n",
    "errors_and_size = np.array(errors_and_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPA as baseline\n",
    "test_ipa = []\n",
    "test_rpa = []\n",
    "for graph in test:\n",
    "    test_ipa.append(graph.ipa.cpu().detach().numpy())\n",
    "    test_rpa.append(graph.y.cpu().detach().numpy())\n",
    "test_ipa = np.stack(test_ipa)\n",
    "test_rpa = np.stack(test_rpa)\n",
    "print(\n",
    "    \"Median MSE[IPA_DFT,RPA_DFT]: \"\n",
    "    + str(np.median(((test_ipa - test_rpa) ** 2).mean(axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median SC[IPA_DFT,RPA_DFT]: \"\n",
    "    + str(\n",
    "        np.median(\n",
    "            1\n",
    "            - np.trapz(np.abs(test_ipa - test_rpa), axis=1)\n",
    "            / np.trapz(abs(test_rpa), axis=1)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate train errors\n",
    "errors_dl_100 = []\n",
    "errors_dl_300 = []\n",
    "errors_dl_1000 = []\n",
    "errors_dl_3000 = []\n",
    "errors_dl_4610 = []\n",
    "\n",
    "errors_tl_100 = []\n",
    "errors_tl_300 = []\n",
    "errors_tl_1000 = []\n",
    "errors_tl_3000 = []\n",
    "errors_tl_4610 = []\n",
    "\n",
    "random.seed(seed)\n",
    "train_100 = random.sample(train, 100)\n",
    "random.seed(seed)\n",
    "train_300 = random.sample(train, 300)\n",
    "random.seed(seed)\n",
    "train_1000 = random.sample(train, 1000)\n",
    "random.seed(seed)\n",
    "train_3000 = random.sample(train, 3000)\n",
    "\n",
    "for graph in train_100:\n",
    "    graph.cuda()\n",
    "    true = graph.y.cpu().detach().numpy()\n",
    "    errors_dl_100.append(model_dl_100(graph).cpu().detach().numpy() - true)\n",
    "    errors_tl_100.append(model_tl_100(graph).cpu().detach().numpy() - true)\n",
    "\n",
    "for graph in train_300:\n",
    "    graph.cuda()\n",
    "    true = graph.y.cpu().detach().numpy()\n",
    "    errors_dl_300.append(model_dl_300(graph).cpu().detach().numpy() - true)\n",
    "    errors_tl_300.append(model_tl_300(graph).cpu().detach().numpy() - true)\n",
    "\n",
    "for graph in train_1000:\n",
    "    graph.cuda()\n",
    "    true = graph.y.cpu().detach().numpy()\n",
    "    errors_dl_1000.append(model_dl_1000(graph).cpu().detach().numpy() - true)\n",
    "    errors_tl_1000.append(model_tl_1000(graph).cpu().detach().numpy() - true)\n",
    "\n",
    "for graph in train_3000:\n",
    "    graph.cuda()\n",
    "    true = graph.y.cpu().detach().numpy()\n",
    "    errors_dl_3000.append(model_dl_3000(graph).cpu().detach().numpy() - true)\n",
    "    errors_tl_3000.append(model_tl_3000(graph).cpu().detach().numpy() - true)\n",
    "\n",
    "for graph in train:\n",
    "    graph.cuda()\n",
    "    true = graph.y.cpu().detach().numpy()\n",
    "    errors_dl_4610.append(model_dl_4610(graph).cpu().detach().numpy() - true)\n",
    "    errors_tl_4610.append(model_tl_4610(graph).cpu().detach().numpy() - true)\n",
    "\n",
    "errors_dl_100 = np.array(errors_dl_100)\n",
    "errors_dl_300 = np.array(errors_dl_300)\n",
    "errors_dl_1000 = np.array(errors_dl_1000)\n",
    "errors_dl_3000 = np.array(errors_dl_3000)\n",
    "errors_dl_4610 = np.array(errors_dl_4610)\n",
    "errors_tl_100 = np.array(errors_tl_100)\n",
    "errors_tl_300 = np.array(errors_tl_300)\n",
    "errors_tl_1000 = np.array(errors_tl_1000)\n",
    "errors_tl_3000 = np.array(errors_tl_3000)\n",
    "errors_tl_4610 = np.array(errors_tl_4610)\n",
    "\n",
    "print(\n",
    "    \"Median train MAE for DL 100: \"\n",
    "    + str(np.median(np.mean(np.abs(errors_dl_100), axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MSE for DL 100: \"\n",
    "    + str(np.median(np.mean((errors_dl_100) ** 2, axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MAE for DL 300: \"\n",
    "    + str(np.median(np.mean(np.abs(errors_dl_300), axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MSE for DL 300: \"\n",
    "    + str(np.median(np.mean((errors_dl_300) ** 2, axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MAE for DL 1000: \"\n",
    "    + str(np.median(np.mean(np.abs(errors_dl_1000), axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MSE for DL 1000: \"\n",
    "    + str(np.median(np.mean((errors_dl_1000) ** 2, axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MAE for DL 3000: \"\n",
    "    + str(np.median(np.mean(np.abs(errors_dl_3000), axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MSE for DL 3000: \"\n",
    "    + str(np.median(np.mean((errors_dl_3000) ** 2, axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MAE for DL 4610: \"\n",
    "    + str(np.median(np.mean(np.abs(errors_dl_4610), axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MSE for DL 4610: \"\n",
    "    + str(np.median(np.mean((errors_dl_4610) ** 2, axis=1)))\n",
    ")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\n",
    "    \"Median train MAE for TL 100: \"\n",
    "    + str(np.median(np.mean(np.abs(errors_tl_100), axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MSE for TL 100: \"\n",
    "    + str(np.median(np.mean((errors_tl_100) ** 2, axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MAE for TL 300: \"\n",
    "    + str(np.median(np.mean(np.abs(errors_tl_300), axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MSE for TL 300: \"\n",
    "    + str(np.median(np.mean((errors_tl_300) ** 2, axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MAE for TL 1000: \"\n",
    "    + str(np.median(np.mean(np.abs(errors_tl_1000), axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MSE for TL 1000: \"\n",
    "    + str(np.median(np.mean((errors_tl_1000) ** 2, axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MAE for TL 3000: \"\n",
    "    + str(np.median(np.mean(np.abs(errors_tl_3000), axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MSE for TL 3000: \"\n",
    "    + str(np.median(np.mean((errors_tl_3000) ** 2, axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MAE for TL 4610: \"\n",
    "    + str(np.median(np.mean(np.abs(errors_tl_4610), axis=1)))\n",
    ")\n",
    "print(\n",
    "    \"Median train MSE for TL 4610: \"\n",
    "    + str(np.median(np.mean((errors_tl_4610) ** 2, axis=1)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"publication.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dl = model_dl_300\n",
    "model_tl = model_tl_300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "lw = 1\n",
    "fig, axes = plt.subplots(3, 3, figsize=[(3 + 3 / 8) * 2, 3])\n",
    "model_tl.cuda()\n",
    "model_dl.cuda()\n",
    "model_dl.eval()\n",
    "model_tl.eval()\n",
    "ipa_rpa_vals = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "titles = []\n",
    "for idx, ax in enumerate(axes.ravel()):\n",
    "    graph_name = results_dl_100.sort_values(\"ipa_rpa\").iloc[\n",
    "        int(ipa_rpa_vals[idx] * len(results_dl_100) + 1)\n",
    "    ][\"name\"][0]\n",
    "    for graph in test:\n",
    "        if graph.mat_id == graph_name:\n",
    "            ax.plot(graph.ipa.cpu(), \"k\", linewidth=lw * 0.5)\n",
    "            ax.plot(graph.y.cpu(), \"k\", linewidth=lw)\n",
    "            ax.plot(\n",
    "                model_dl_300(graph.cuda()).cpu().detach().numpy().flatten(),\n",
    "                color=\"limegreen\",\n",
    "                linewidth=lw * 0.5,\n",
    "            )\n",
    "            ax.plot(\n",
    "                model_dl_4610(graph.cuda()).cpu().detach().numpy().flatten(),\n",
    "                color=\"limegreen\",\n",
    "                linestyle=\"--\",\n",
    "                linewidth=lw,\n",
    "            )\n",
    "            ax.plot(\n",
    "                model_tl_300(graph.cuda()).cpu().detach().numpy().flatten(),\n",
    "                color=\"tab:orange\",\n",
    "                linewidth=lw * 0.5,\n",
    "            )\n",
    "            ax.plot(\n",
    "                model_tl_4610(graph.cuda()).cpu().detach().numpy().flatten(),\n",
    "                color=\"tab:orange\",\n",
    "                linestyle=\"--\",\n",
    "                linewidth=lw,\n",
    "            )\n",
    "\n",
    "            titles.append(graph[\"mat_id\"][5:])\n",
    "            ax.set_ylim(bottom=0, top=ax.get_ylim()[1] * 1.2)\n",
    "            ax.set_xlim([0, 1000])\n",
    "            ax.set_xticks([0, 200, 400, 600, 800, 1000])\n",
    "            ax.set_xticklabels([0, 2, 4, 6, 8, 10])\n",
    "            ax.annotate(\n",
    "                re.sub(\n",
    "                    r\"(\\d+)\",\n",
    "                    r\"$_{\\1}$\",\n",
    "                    data_df[data_df[\"mat_id\"] == graph_name].formula.values[0],\n",
    "                ),\n",
    "                xy=(1, 1),\n",
    "                xycoords=\"axes fraction\",\n",
    "                xytext=(-4, -4),\n",
    "                textcoords=\"offset points\",\n",
    "                ha=\"right\",\n",
    "                va=\"top\",\n",
    "                fontsize=8,\n",
    "                clip_on=False,\n",
    "            )\n",
    "\n",
    "\n",
    "axes.ravel()[0].annotate(\"$Q_{10\\%}$ \", xy=[0.05, 0.85], xycoords=\"axes fraction\")\n",
    "axes.ravel()[1].annotate(\"$Q_{20\\%}$ \", xy=[0.05, 0.85], xycoords=\"axes fraction\")\n",
    "axes.ravel()[2].annotate(\"$Q_{30\\%}$ \", xy=[0.05, 0.85], xycoords=\"axes fraction\")\n",
    "axes.ravel()[3].annotate(\"$Q_{40\\%}$ \", xy=[0.05, 0.85], xycoords=\"axes fraction\")\n",
    "axes.ravel()[4].annotate(\"$Q_{50\\%}$ \", xy=[0.05, 0.85], xycoords=\"axes fraction\")\n",
    "axes.ravel()[5].annotate(\"$Q_{60\\%}$ \", xy=[0.05, 0.85], xycoords=\"axes fraction\")\n",
    "axes.ravel()[6].annotate(\"$Q_{70\\%}$ \", xy=[0.05, 0.85], xycoords=\"axes fraction\")\n",
    "axes.ravel()[7].annotate(\"$Q_{80\\%}$ \", xy=[0.05, 0.85], xycoords=\"axes fraction\")\n",
    "axes.ravel()[8].annotate(\"$Q_{90\\%}$ \", xy=[0.05, 0.85], xycoords=\"axes fraction\")\n",
    "\n",
    "\n",
    "legend_handles = [\n",
    "    Line2D([0], [0], color=\"k\", lw=lw * 1.5, label=\"RPA (target)\"),\n",
    "    Line2D([0], [0], color=\"k\", lw=lw * 0.5, label=\"IPA\"),\n",
    "    Line2D([0], [0], color=\"limegreen\", lw=lw * 0.5, label=\"DL ($N=300$)\"),\n",
    "    Line2D([0], [0], color=\"limegreen\", lw=lw, linestyle=\"--\", label=\"DL ($N=4610$)\"),\n",
    "    Line2D([0], [0], color=\"tab:orange\", lw=lw * 0.5, label=\"TL ($N=300$)\"),\n",
    "    Line2D([0], [0], color=\"tab:orange\", lw=lw, linestyle=\"--\", label=\"TL ($N=4610$)\"),\n",
    "]\n",
    "\n",
    "\n",
    "fig.legend(\n",
    "    handles=legend_handles,\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(0.85, 0.51),\n",
    "    frameon=False,\n",
    ")\n",
    "\n",
    "\n",
    "# set y-ticks manually\n",
    "axes[0, 0].set_yticks([0, 5, 10])\n",
    "axes[1, 0].set_yticks([0, 5, 10])\n",
    "axes[2, 0].set_yticks([0, 10, 20])\n",
    "axes[0, 1].set_yticks([0, 3, 6])\n",
    "axes[1, 1].set_yticks([0, 5, 10, 15])\n",
    "axes[2, 1].set_yticks([0, 5, 10])\n",
    "axes[0, 2].set_yticks([0, 2, 4])\n",
    "axes[1, 2].set_yticks([0, 5, 10])\n",
    "axes[2, 2].set_yticks([0, 3, 6])\n",
    "\n",
    "fig.supxlabel(r\"Energy (eV)\", x=0.45, y=-0.01)\n",
    "fig.supylabel(r\"$\\mathrm{Im}(\\overline{\\varepsilon})$\", x=-0.005, y=0.53)\n",
    "fig.tight_layout(pad=0.0, w_pad=0.2, h_pad=0.3, rect=[0, 0, 0.85, 1])\n",
    "fig.show()\n",
    "fig.savefig(\"plots/Fig1_revised.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "lw = 1\n",
    "fig, axes = plt.subplots(3, 1, figsize=[(3 + 3 / 8), 7])\n",
    "\n",
    "\n",
    "# Top plot\n",
    "x_vals = np.array([100, 300, 1000, 3000, 4610])\n",
    "x_vals_small = np.array([74, 343, 1470, 2191, 2699])\n",
    "y_vals_small = np.array([0.791, 0.848, 0.870, 0.879, 0.884])\n",
    "y_vals_dl = np.array([0.716, 0.754, 0.827, 0.874, 0.900])\n",
    "y_vals_tl = np.array([0.834, 0.863, 0.881, 0.893, 0.893])\n",
    "axes[0].set_xscale(\"log\")\n",
    "\n",
    "axes[0].plot(x_vals, y_vals_dl, marker=\"*\", color=\"limegreen\", label=\"Direct Learning\")\n",
    "axes[0].plot(\n",
    "    x_vals, y_vals_tl, marker=\"*\", color=\"tab:orange\", label=\"Transfer Learning\"\n",
    ")\n",
    "axes[0].plot(\n",
    "    x_vals_small, y_vals_small, marker=\"*\", color=\"tab:blue\", label=\"TL on small cells\"\n",
    ")\n",
    "axes[0].plot([0, 10000], [0.6896362, 0.6896362], \"k--\", label=\"IPA baseline\")\n",
    "\n",
    "axes[0].set_xlabel(\"Training Set Size\")\n",
    "axes[0].set_ylabel(\"Median SC[RPA$_\\mathrm{ML}$;RPA$_\\mathrm{DFT}]$\")\n",
    "axes[0].set_yticks([0.7, 0.75, 0.8, 0.85, 0.9])\n",
    "axes[0].legend()\n",
    "\n",
    "axes[0].annotate(2, xy=[x_vals_small[0], y_vals_small[0] - 0.01])\n",
    "axes[0].annotate(3, xy=[x_vals_small[1], y_vals_small[1] - 0.01])\n",
    "axes[0].annotate(4, xy=[x_vals_small[2], y_vals_small[2] - 0.01])\n",
    "axes[0].annotate(5, xy=[x_vals_small[3], y_vals_small[3] - 0.01])\n",
    "axes[0].annotate(6, xy=[x_vals_small[4] + 200, y_vals_small[4] - 0.005])\n",
    "\n",
    "axes[0].set_xlim([60, 6000])\n",
    "\n",
    "# Middle plot\n",
    "y_vals_small = np.array([0.225, 0.117, 0.086, 0.079, 0.075])\n",
    "y_vals_dl = np.array([0.394, 0.262, 0.160, 0.075, 0.052])\n",
    "y_vals_tl = np.array([0.133, 0.101, 0.077, 0.059, 0.061])\n",
    "axes[1].set_xscale(\"log\")\n",
    "axes[1].set_yscale(\"log\")\n",
    "\n",
    "axes[1].plot(x_vals, y_vals_dl, marker=\"*\", color=\"limegreen\", label=\"Direct Learning\")\n",
    "axes[1].plot(\n",
    "    x_vals, y_vals_tl, marker=\"*\", color=\"tab:orange\", label=\"Transfer Learning\"\n",
    ")\n",
    "axes[1].plot(\n",
    "    x_vals_small, y_vals_small, marker=\"*\", color=\"tab:blue\", label=\"TL on small cells\"\n",
    ")\n",
    "axes[1].plot([0, 10000], [0.46935984, 0.46935984], \"k--\", label=\"IPA baseline\")\n",
    "\n",
    "axes[1].set_xlabel(\"Training Set Size\")\n",
    "axes[1].set_ylabel(\"Median MSE[RPA$_\\mathrm{ML}$;RPA$_\\mathrm{DFT}$]\", labelpad=-3)\n",
    "axes[1].set_yticks([5e-2, 6e-2, 0.1, 0.2, 0.3, 0.4])\n",
    "axes[1].set_yticklabels([\"0.05\", \"\", \"0.1\", \"0.2\", \"0.3\", \"0.4\"])\n",
    "\n",
    "# axes[1].legend()\n",
    "\n",
    "axes[1].annotate(2, xy=[x_vals_small[0] + 1, y_vals_small[0] + 0.005])\n",
    "axes[1].annotate(3, xy=[x_vals_small[1], y_vals_small[1] + 0.005])\n",
    "axes[1].annotate(4, xy=[x_vals_small[2], y_vals_small[2] + 0.005])\n",
    "axes[1].annotate(5, xy=[x_vals_small[3], y_vals_small[3] + 0.005])\n",
    "axes[1].annotate(6, xy=[x_vals_small[4], y_vals_small[4] + 0.005])\n",
    "\n",
    "axes[1].set_xlim([60, 6000])\n",
    "\n",
    "# Bottom plot\n",
    "# Version without inset\n",
    "\n",
    "axes2 = axes[2].twinx()\n",
    "axes2.set_zorder(0)\n",
    "axes[2].set_zorder(1)\n",
    "axes[2].patch.set_alpha(0)\n",
    "axes2.patch.set_visible(False)\n",
    "\n",
    "sc_list = [\n",
    "    list_of_lists[2][:, 1],\n",
    "    list_of_lists[3][:, 1],\n",
    "    list_of_lists[4][:, 1],\n",
    "    list_of_lists[5][:, 1],\n",
    "    list_of_lists[6][:, 1],\n",
    "    list_of_lists[7][:, 1],\n",
    "]\n",
    "mse_list = [\n",
    "    list_of_lists[2][:, 0],\n",
    "    list_of_lists[3][:, 0],\n",
    "    list_of_lists[4][:, 0],\n",
    "    list_of_lists[5][:, 0],\n",
    "    list_of_lists[6][:, 0],\n",
    "    list_of_lists[7][:, 0],\n",
    "]\n",
    "axes[2].boxplot(sc_list, showfliers=False)\n",
    "axes[2].set_xlabel(\"Atoms per unit cell\")\n",
    "axes[2].set_ylabel(\"SC[RPA$_\\mathrm{ML}$;RPA$_\\mathrm{DFT}$]\")\n",
    "axes[2].set_xticks([1, 2, 3, 4, 5, 6])\n",
    "axes[2].set_xticklabels([3, 4, 5, 6, 7, 8])\n",
    "axes[2].set_ylim([0.3, 1])\n",
    "axes2.set_ylim([0, 300])\n",
    "axes2.set_xlim([0, 7])\n",
    "\n",
    "axes2.hist(\n",
    "    errors_and_size[:, 2] - 2,\n",
    "    bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5, 6.5, 7.5, 8.5],\n",
    "    color=\"tab:blue\",\n",
    ")\n",
    "axes2.set_ylabel(\"Occurence in test set\")\n",
    "\n",
    "\n",
    "fig.tight_layout(w_pad=1, h_pad=0.5)\n",
    "plt.show()\n",
    "fig.savefig(\"plots/Fig2_revised.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ipa.eval()\n",
    "model_ipa.cuda()\n",
    "model_dl_300.eval()\n",
    "model_dl_300.cuda()\n",
    "model_tl_300.eval()\n",
    "model_tl_300.cuda()\n",
    "rows = []\n",
    "for graph in test:\n",
    "    cdict = {}\n",
    "    graph.cuda()\n",
    "    cdict[\"ipa_true\"] = graph.ipa.cpu().numpy()\n",
    "    cdict[\"rpa_true\"] = graph.y.cpu().numpy()\n",
    "    cdict[\"ipa_pred\"] = model_ipa(graph).cpu().detach().numpy()\n",
    "    cdict[\"dl_pred\"] = model_dl_300(graph).cpu().detach().numpy()\n",
    "    cdict[\"tl_pred\"] = model_tl_300(graph).cpu().detach().numpy()\n",
    "    rows.append(cdict)\n",
    "comp_df_300 = pd.DataFrame(rows)\n",
    "comp_df_300[\"iptrue_rptrue\"] = get_sc(comp_df_300[\"ipa_true\"], comp_df_300[\"rpa_true\"])\n",
    "comp_df_300[\"ippred_iptrue\"] = get_sc(comp_df_300[\"ipa_pred\"], comp_df_300[\"ipa_true\"])\n",
    "comp_df_300[\"dlpred_rptrue\"] = get_sc(comp_df_300[\"dl_pred\"], comp_df_300[\"rpa_true\"])\n",
    "comp_df_300[\"tlpred_rptrue\"] = get_sc(comp_df_300[\"tl_pred\"], comp_df_300[\"rpa_true\"])\n",
    "\n",
    "model_dl_4610.eval()\n",
    "model_dl_4610.cuda()\n",
    "model_tl_4610.eval()\n",
    "model_tl_4610.cuda()\n",
    "rows = []\n",
    "for graph in test:\n",
    "    cdict = {}\n",
    "    graph.cuda()\n",
    "    cdict[\"ipa_true\"] = graph.ipa.cpu().numpy()\n",
    "    cdict[\"rpa_true\"] = graph.y.cpu().numpy()\n",
    "    cdict[\"ipa_pred\"] = model_ipa(graph).cpu().detach().numpy()\n",
    "    cdict[\"dl_pred\"] = model_dl_4610(graph).cpu().detach().numpy()\n",
    "    cdict[\"tl_pred\"] = model_tl_4610(graph).cpu().detach().numpy()\n",
    "    rows.append(cdict)\n",
    "comp_df_4610 = pd.DataFrame(rows)\n",
    "comp_df_4610[\"iptrue_rptrue\"] = get_sc(\n",
    "    comp_df_4610[\"ipa_true\"], comp_df_4610[\"rpa_true\"]\n",
    ")\n",
    "comp_df_4610[\"ippred_iptrue\"] = get_sc(\n",
    "    comp_df_4610[\"ipa_pred\"], comp_df_4610[\"ipa_true\"]\n",
    ")\n",
    "comp_df_4610[\"dlpred_rptrue\"] = get_sc(\n",
    "    comp_df_4610[\"dl_pred\"], comp_df_4610[\"rpa_true\"]\n",
    ")\n",
    "comp_df_4610[\"tlpred_rptrue\"] = get_sc(\n",
    "    comp_df_4610[\"tl_pred\"], comp_df_4610[\"rpa_true\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    3,\n",
    "    3,\n",
    "    figsize=[2 * (3 + 3 / 8), 6],\n",
    "    gridspec_kw={\"width_ratios\": [2, 2, 0.4], \"height_ratios\": [0.4, 2, 2]},\n",
    ")\n",
    "axes = axes.ravel()\n",
    "bins = np.linspace(0, 1, 51)\n",
    "cmp = \"Blues\"\n",
    "comp_df = comp_df_300\n",
    "\n",
    "axes[0].hist(comp_df[\"dlpred_rptrue\"], bins=bins, color=\"tab:blue\")\n",
    "axes[1].hist(comp_df[\"tlpred_rptrue\"], bins=bins, color=\"tab:blue\")\n",
    "axes[5].hist(\n",
    "    comp_df[\"iptrue_rptrue\"], bins=bins, orientation=\"horizontal\", color=\"tab:blue\"\n",
    ")\n",
    "axes[8].hist(\n",
    "    comp_df[\"ippred_iptrue\"], bins=bins, orientation=\"horizontal\", color=\"tab:blue\"\n",
    ")\n",
    "\n",
    "\n",
    "X = \"dlpred_rptrue\"\n",
    "Y = \"iptrue_rptrue\"\n",
    "axes[3].hist2d(comp_df[X], comp_df[Y], bins=bins, cmap=cmp)\n",
    "axes[3].plot([0, 1], [0, 1], color=\"tab:orange\", ls=\"--\", alpha=0.7)\n",
    "axes[3].set_ylabel(\"SC[IPA$_\\mathrm{DFT}$;RPA$_\\mathrm{DFT}$]\")\n",
    "\n",
    "X = \"tlpred_rptrue\"\n",
    "Y = \"iptrue_rptrue\"\n",
    "axes[4].hist2d(comp_df[X], comp_df[Y], bins=bins, cmap=cmp)\n",
    "axes[4].plot([0, 1], [0, 1], color=\"tab:orange\", ls=\"--\", alpha=0.7)\n",
    "\n",
    "X = \"dlpred_rptrue\"\n",
    "Y = \"ippred_iptrue\"\n",
    "axes[6].hist2d(comp_df[X], comp_df[Y], bins=bins, cmap=cmp)\n",
    "axes[6].plot([0, 1], [0, 1], color=\"tab:orange\", ls=\"--\", alpha=0.7)\n",
    "axes[6].set_xlabel(\"SC[RPA$_\\mathrm{DL}$;RPA$_\\mathrm{DFT}$]\")\n",
    "axes[6].set_ylabel(\"SC[IPA$_\\mathrm{ML}$;IPA$_\\mathrm{DFT}$]\")\n",
    "\n",
    "X = \"tlpred_rptrue\"\n",
    "Y = \"ippred_iptrue\"\n",
    "axes[7].hist2d(comp_df[X], comp_df[Y], bins=bins, cmap=cmp)\n",
    "axes[7].plot([0, 1], [0, 1], color=\"tab:orange\", ls=\"--\", alpha=0.7)\n",
    "axes[7].set_xlabel(\"SC[RPA$_\\mathrm{TL}$;RPA$_\\mathrm{DFT}$]\")\n",
    "\n",
    "\n",
    "axes[0].grid(False)\n",
    "axes[1].grid(False)\n",
    "axes[5].grid(False)\n",
    "axes[8].grid(False)\n",
    "\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "axes[0].set_xlim([0, 1])\n",
    "axes[1].set_xlim([0, 1])\n",
    "axes[5].set_ylim([0, 1])\n",
    "axes[8].set_ylim([0, 1])\n",
    "\n",
    "axes[3].set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "axes[6].set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "axes[6].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "axes[7].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "labelfs = 10\n",
    "axes[0].annotate(\n",
    "    r\"$\\mathbf{a}$\", [0.02, 0.7], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "axes[1].annotate(\n",
    "    r\"$\\mathbf{b}$\", [0.02, 0.7], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "axes[5].annotate(\n",
    "    r\"$\\mathbf{c}$\", [0.72, 0.95], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "axes[8].annotate(\n",
    "    r\"$\\mathbf{d}$\", [0.72, 0.95], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "\n",
    "axes[3].annotate(\n",
    "    r\"$\\mathbf{ac}$\", [0.02, 0.93], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "axes[4].annotate(\n",
    "    r\"$\\mathbf{bc}$\", [0.02, 0.93], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "axes[6].annotate(\n",
    "    r\"$\\mathbf{ad}$\", [0.02, 0.93], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "axes[7].annotate(\n",
    "    r\"$\\mathbf{bd}$\", [0.02, 0.93], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.07, hspace=0.07)\n",
    "\n",
    "fig.savefig(\"plots/Fig3.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    3,\n",
    "    3,\n",
    "    figsize=[2 * (3 + 3 / 8), 6],\n",
    "    gridspec_kw={\"width_ratios\": [2, 2, 0.4], \"height_ratios\": [0.4, 2, 2]},\n",
    ")\n",
    "axes = axes.ravel()\n",
    "bins = np.linspace(0, 1, 51)\n",
    "cmp = \"Blues\"\n",
    "comp_df = comp_df_4610\n",
    "\n",
    "axes[0].hist(comp_df[\"dlpred_rptrue\"], bins=bins, color=\"tab:blue\")\n",
    "axes[1].hist(comp_df[\"tlpred_rptrue\"], bins=bins, color=\"tab:blue\")\n",
    "axes[5].hist(\n",
    "    comp_df[\"iptrue_rptrue\"], bins=bins, orientation=\"horizontal\", color=\"tab:blue\"\n",
    ")\n",
    "axes[8].hist(\n",
    "    comp_df[\"ippred_iptrue\"], bins=bins, orientation=\"horizontal\", color=\"tab:blue\"\n",
    ")\n",
    "\n",
    "\n",
    "X = \"dlpred_rptrue\"\n",
    "Y = \"iptrue_rptrue\"\n",
    "axes[3].hist2d(comp_df[X], comp_df[Y], bins=bins, cmap=cmp)\n",
    "axes[3].plot([0, 1], [0, 1], color=\"tab:orange\", ls=\"--\", alpha=0.7)\n",
    "axes[3].set_ylabel(\"SC[IPA$_\\mathrm{DFT}$;RPA$_\\mathrm{DFT}$]\")\n",
    "\n",
    "X = \"tlpred_rptrue\"\n",
    "Y = \"iptrue_rptrue\"\n",
    "axes[4].hist2d(comp_df[X], comp_df[Y], bins=bins, cmap=cmp)\n",
    "axes[4].plot([0, 1], [0, 1], color=\"tab:orange\", ls=\"--\", alpha=0.7)\n",
    "\n",
    "X = \"dlpred_rptrue\"\n",
    "Y = \"ippred_iptrue\"\n",
    "axes[6].hist2d(comp_df[X], comp_df[Y], bins=bins, cmap=cmp)\n",
    "axes[6].plot([0, 1], [0, 1], color=\"tab:orange\", ls=\"--\", alpha=0.7)\n",
    "axes[6].set_xlabel(\"SC[RPA$_\\mathrm{DL}$;RPA$_\\mathrm{DFT}$]\")\n",
    "axes[6].set_ylabel(\"SC[IPA$_\\mathrm{ML}$;IPA$_\\mathrm{DFT}$]\")\n",
    "\n",
    "X = \"tlpred_rptrue\"\n",
    "Y = \"ippred_iptrue\"\n",
    "axes[7].hist2d(comp_df[X], comp_df[Y], bins=bins, cmap=cmp)\n",
    "axes[7].plot([0, 1], [0, 1], color=\"tab:orange\", ls=\"--\", alpha=0.7)\n",
    "axes[7].set_xlabel(\"SC[RPA$_\\mathrm{TL}$;RPA$_\\mathrm{DFT}$]\")\n",
    "\n",
    "\n",
    "axes[0].grid(False)\n",
    "axes[1].grid(False)\n",
    "axes[5].grid(False)\n",
    "axes[8].grid(False)\n",
    "\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "axes[0].set_xlim([0, 1])\n",
    "axes[1].set_xlim([0, 1])\n",
    "axes[5].set_ylim([0, 1])\n",
    "axes[8].set_ylim([0, 1])\n",
    "\n",
    "axes[3].set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "axes[6].set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "axes[6].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "axes[7].set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "labelfs = 10\n",
    "axes[0].annotate(\n",
    "    r\"$\\mathbf{a}$\", [0.02, 0.7], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "axes[1].annotate(\n",
    "    r\"$\\mathbf{b}$\", [0.02, 0.7], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "axes[5].annotate(\n",
    "    r\"$\\mathbf{c}$\", [0.72, 0.95], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "axes[8].annotate(\n",
    "    r\"$\\mathbf{d}$\", [0.72, 0.95], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "\n",
    "axes[3].annotate(\n",
    "    r\"$\\mathbf{ac}$\", [0.02, 0.93], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "axes[4].annotate(\n",
    "    r\"$\\mathbf{bc}$\", [0.02, 0.93], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "axes[6].annotate(\n",
    "    r\"$\\mathbf{ad}$\", [0.02, 0.93], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "axes[7].annotate(\n",
    "    r\"$\\mathbf{bd}$\", [0.02, 0.93], xycoords=\"axes fraction\", fontsize=labelfs\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.07, hspace=0.07)\n",
    "\n",
    "fig.savefig(\"plots/SFig1.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \"dlpred_rptrue\"\n",
    "Y = \"tlpred_rptrue\"\n",
    "\n",
    "cmp = \"Blues\"\n",
    "bins = np.linspace(0, 1, 51)\n",
    "fig, axes = plt.subplots(1, 2, figsize=[2 * (3 + 3 / 8), 3])\n",
    "axes = axes.ravel()\n",
    "\n",
    "axes[0].hist2d(comp_df_300[X], comp_df_300[Y], bins=bins, cmap=cmp)\n",
    "axes[0].plot([0, 1], [0, 1], color=\"tab:orange\", ls=\"--\", alpha=0.7)\n",
    "axes[0].set_xlabel(\"SC[RPA$_\\mathrm{DL}$;RPA$_\\mathrm{DFT}$]\")\n",
    "axes[0].set_ylabel(\"SC[RPA$_\\mathrm{TL}$;RPA$_\\mathrm{DFT}$]\")\n",
    "\n",
    "axes[1].hist2d(comp_df_4610[X], comp_df_4610[Y], bins=bins, cmap=cmp)\n",
    "axes[1].plot([0, 1], [0, 1], color=\"tab:orange\", ls=\"--\", alpha=0.7)\n",
    "axes[1].set_xlabel(\"SC[RPA$_\\mathrm{DL}$;RPA$_\\mathrm{DFT}$]\")\n",
    "axes[1].set_ylabel(\"SC[RPA$_\\mathrm{TL}$;RPA$_\\mathrm{DFT}$]\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"plots/Fig4.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "pred_tl_300 = []\n",
    "pred_tl_4610 = []\n",
    "pred_dl_300 = []\n",
    "pred_dl_4610 = []\n",
    "\n",
    "for graph in test:\n",
    "    true.append(graph.y.cpu().detach().numpy())\n",
    "    pred_tl_300.append(model_tl_300(graph.cuda()).cpu().detach().numpy())\n",
    "    pred_tl_4610.append(model_tl_4610(graph.cuda()).cpu().detach().numpy())\n",
    "    pred_dl_300.append(model_dl_300(graph.cuda()).cpu().detach().numpy())\n",
    "    pred_dl_4610.append(model_dl_4610(graph.cuda()).cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=[2 * (3 + 3 / 8), 3 * 2])\n",
    "axes[0, 0].scatter(\n",
    "    np.trapz(true, dx=0.01, axis=1),\n",
    "    np.trapz(pred_tl_300, dx=0.01, axis=1),\n",
    "    s=0.5,\n",
    "    color=\"tab:blue\",\n",
    ")\n",
    "axes[0, 0].set_title(\"TL: 300\")\n",
    "axes[0, 1].scatter(\n",
    "    np.trapz(true, dx=0.01, axis=1),\n",
    "    np.trapz(pred_dl_300, dx=0.01, axis=1),\n",
    "    s=0.5,\n",
    "    color=\"tab:blue\",\n",
    ")\n",
    "axes[0, 1].set_title(\"DL: 300\")\n",
    "axes[1, 0].scatter(\n",
    "    np.trapz(true, dx=0.01, axis=1),\n",
    "    np.trapz(pred_tl_4610, dx=0.01, axis=1),\n",
    "    s=0.5,\n",
    "    color=\"tab:blue\",\n",
    ")\n",
    "axes[1, 0].set_title(\"TL: 4610\")\n",
    "axes[1, 1].scatter(\n",
    "    np.trapz(true, dx=0.01, axis=1),\n",
    "    np.trapz(pred_dl_4610, dx=0.01, axis=1),\n",
    "    s=0.5,\n",
    "    color=\"tab:blue\",\n",
    ")\n",
    "axes[1, 1].set_title(\"DL: 4610\")\n",
    "\n",
    "for ax in axes.ravel():\n",
    "    ax.plot([0, 100], [0, 100], color=\"tab:orange\")\n",
    "    ax.set_xlim([0, 160])\n",
    "    ax.set_ylim([0, 100])\n",
    "    ax.set_xlabel(r\"QW$_\\mathrm{DFT}$\")\n",
    "    ax.set_ylabel(r\"QW$_\\mathrm{ML}$\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"plots/SFig4.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the runtime of a model on your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.core import Structure\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "model_dl_4610.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Load the cif\n",
    "structure = Structure.from_file(\"otherstructs/agm004850436.cif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure = Structure.from_file(\"otherstructs/agm004850436.cif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Create the graph\n",
    "nbr_fea_idx = []\n",
    "nbr_fea = []\n",
    "\n",
    "self_fea_idx = []\n",
    "\n",
    "all_nbrs = structure.get_all_neighbors(5)\n",
    "for site, nbr in enumerate(all_nbrs):\n",
    "    nbr_fea_idx_sub, nbr_fea_sub, self_fea_idx_sub = [], [], []\n",
    "\n",
    "    for n in range(len(nbr)):\n",
    "        self_fea_idx_sub.append(site)\n",
    "\n",
    "    for j in range(len(nbr)):\n",
    "        nbr_fea_idx_sub.append(nbr[j][2])\n",
    "\n",
    "    for j in range(len(nbr)):\n",
    "        nbr_fea_sub.append(nbr[j][1])\n",
    "\n",
    "    nbr_fea_idx.append(nbr_fea_idx_sub)\n",
    "    nbr_fea.append(nbr_fea_sub)\n",
    "\n",
    "    self_fea_idx.append(self_fea_idx_sub)\n",
    "\n",
    "edges = torch.stack(\n",
    "    (\n",
    "        torch.tensor(\n",
    "            [item for items in self_fea_idx for item in items], dtype=torch.long\n",
    "        ),\n",
    "        torch.tensor(\n",
    "            [item for items in nbr_fea_idx for item in items], dtype=torch.long\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "nbr_fea = [item for items in nbr_fea for item in items]\n",
    "x_vals = np.linspace(0, 5, 51)\n",
    "edge_attr = np.sqrt(10 / np.pi) * np.array(\n",
    "    [np.exp(-10 * (nbr_fea - val) ** 2) for val in x_vals]\n",
    ")\n",
    "edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "edge_attr = torch.transpose(edge_attr, 0, 1)\n",
    "\n",
    "atoms = np.array(range(len(all_nbrs)))\n",
    "self_fea = []\n",
    "\n",
    "for atom_id in atoms:\n",
    "    # encode atom information by group and row\n",
    "    group = torch.tensor(\n",
    "        structure.species[atom_id].group - 1, dtype=torch.int64)\n",
    "    if group > 1:\n",
    "        group -= 10\n",
    "    row = torch.tensor(\n",
    "        structure.species[atom_id].row - 1, dtype=torch.int64)\n",
    "    group = torch.nn.functional.one_hot(group, num_classes=8)\n",
    "    row = torch.nn.functional.one_hot(row, num_classes=5)\n",
    "    self_fea.append(torch.hstack([group, row]))\n",
    "\n",
    "self_fea = torch.vstack(self_fea)\n",
    "nbr_fea = torch.tensor(nbr_fea, dtype=torch.float)\n",
    "edge_attr = edge_attr\n",
    "\n",
    "graph = Data(\n",
    "    x=self_fea.to(torch.float32),\n",
    "    edge_index=edges,\n",
    "    edge_attr=edge_attr,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "nbr_fea_idx = []\n",
    "nbr_fea = []\n",
    "\n",
    "self_fea_idx = []\n",
    "\n",
    "all_nbrs = structure.get_all_neighbors(5)\n",
    "for site, nbr in enumerate(all_nbrs):\n",
    "    nbr_fea_idx_sub, nbr_fea_sub, self_fea_idx_sub = [], [], []\n",
    "\n",
    "    for n in range(len(nbr)):\n",
    "        self_fea_idx_sub.append(site)\n",
    "\n",
    "    for j in range(len(nbr)):\n",
    "        nbr_fea_idx_sub.append(nbr[j][2])\n",
    "\n",
    "    for j in range(len(nbr)):\n",
    "        nbr_fea_sub.append(nbr[j][1])\n",
    "\n",
    "    nbr_fea_idx.append(nbr_fea_idx_sub)\n",
    "    nbr_fea.append(nbr_fea_sub)\n",
    "\n",
    "    self_fea_idx.append(self_fea_idx_sub)\n",
    "\n",
    "edges = torch.stack(\n",
    "    (\n",
    "        torch.tensor(\n",
    "            [item for items in self_fea_idx for item in items], dtype=torch.long\n",
    "        ),\n",
    "        torch.tensor(\n",
    "            [item for items in nbr_fea_idx for item in items], dtype=torch.long\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "nbr_fea = [item for items in nbr_fea for item in items]\n",
    "x_vals = np.linspace(0, 5, 51)\n",
    "edge_attr = np.sqrt(10 / np.pi) * np.array(\n",
    "    [np.exp(-10 * (nbr_fea - val) ** 2) for val in x_vals]\n",
    ")\n",
    "edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "edge_attr = torch.transpose(edge_attr, 0, 1)\n",
    "\n",
    "atoms = np.array(range(len(all_nbrs)))\n",
    "self_fea = []\n",
    "\n",
    "for atom_id in atoms:\n",
    "    # encode atom information by group and row\n",
    "    group = torch.tensor(structure.species[atom_id].group - 1, dtype=torch.int64)\n",
    "    if group > 1:\n",
    "        group -= 10\n",
    "    row = torch.tensor(structure.species[atom_id].row - 1, dtype=torch.int64)\n",
    "    group = torch.nn.functional.one_hot(group, num_classes=8)\n",
    "    row = torch.nn.functional.one_hot(row, num_classes=5)\n",
    "    self_fea.append(torch.hstack([group, row]))\n",
    "\n",
    "self_fea = torch.vstack(self_fea)\n",
    "nbr_fea = torch.tensor(nbr_fea, dtype=torch.float)\n",
    "edge_attr = edge_attr\n",
    "\n",
    "graph = Data(\n",
    "    x=self_fea.to(torch.float32),\n",
    "    edge_index=edges,\n",
    "    edge_attr=edge_attr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "model_dl_4610(graph.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn the SC between IPA and RPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the graphs to have SC[RPA;IPA] as target\n",
    "with open(\"database/graphs_300_rpa.pckl\", \"rb\") as graph_file:\n",
    "    graphs = pickle.load(graph_file)\n",
    "data_df = pd.read_pickle(\"database/data_300_rpa.pckl\")\n",
    "\n",
    "for graph in graphs:\n",
    "    graph.y = torch.tensor(\n",
    "        1 - np.trapz(np.abs(graph.y - graph.ipa)) / np.trapz(abs(graph.ipa))\n",
    "    )\n",
    "\n",
    "train, val, test = utils.train_val_test(graphs)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the SC model\n",
    "model_sc = models.LitGatNN(lr=1e-3, decay=0, params=params_ipa)\n",
    "\n",
    "out = torch_geometric.nn.Sequential(\n",
    "    \"x\",\n",
    "    [\n",
    "        (\n",
    "            torch_geometric.nn.MLP(\n",
    "                [params_ipa[-2][0] * params_ipa[-2][1]] + params_ipa[-1] + [1],\n",
    "                act=\"relu\",\n",
    "            ),\n",
    "            \"x -> x\",\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "model_sc.gatnn.mlp1 = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a SC model\n",
    "# as before, you don't need to run this cell\n",
    "# as a trained state_dict is already provided\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_callback = L.callbacks.ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "    monitor=\"valid\",\n",
    "    mode=\"min\",\n",
    "    dirpath=\"ckpts\",\n",
    "\n",
    "    filename=\"{epoch:02d}-{valid:.2f}\",\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "TrainLoader = torch_geometric.loader.DataLoader(\n",
    "    train, batch_size=64, shuffle=True, drop_last=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "ValLoader = torch_geometric.loader.DataLoader(val, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "TestLoader = torch_geometric.loader.DataLoader(val, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=200,\n",
    "    check_val_every_n_epoch=20,\n",
    "    precision=\"bf16-mixed\",\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer.fit(model=model_sc, train_dataloaders=TrainLoader, val_dataloaders=ValLoader)\n",
    "\n",
    "\n",
    "checkpoint = torch.load(checkpoint_callback.best_model_path)\n",
    "\n",
    "\n",
    "model_sc.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "\n",
    "# torch.save(model_sc.state_dict(), f\"trained_models/dl_sc.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sc model\n",
    "state_dict = torch.load(\"trained_models/dl_sc.pt\")\n",
    "model_sc.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "model_sc.cuda()\n",
    "model_sc.eval()\n",
    "real = []\n",
    "preds = []\n",
    "for graph in test:\n",
    "    graph.cuda()\n",
    "    real.append(graph.y.cpu().detach().numpy())\n",
    "    preds.append(model_sc(graph).cpu().detach().numpy()[0])\n",
    "real = np.array(real)\n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5\n",
    "fig = plt.Figure(figsize=[3 + 3 / 8, 3 + 3 / 8])\n",
    "plt.hist2d(\n",
    "    np.array(real),\n",
    "    np.array(preds).flatten(),\n",
    "    bins=np.linspace(0.18, 1, 50),\n",
    "    cmap=\"Blues\",\n",
    ")\n",
    "plt.plot([0.0, 1], [0.0, 1], c=\"tab:orange\", linestyle=\"--\", linewidth=1)\n",
    "plt.xlim([0.18, 1])\n",
    "plt.ylim([0.18, 1])\n",
    "plt.xlabel(\"SC[RPA$_\\mathrm{DFT}$;IPA$_\\mathrm{DFT}$]\")\n",
    "plt.ylabel(\"Model Prediction\")\n",
    "plt.savefig(\"plots/Fig5_revised.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean absolute error is: \" + str(np.mean(np.abs(real - preds))))\n",
    "print(\"The median absolute error is: \" + str(np.median(np.abs(real - preds))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for any correlations between SC[IPA,RPA] and materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a sc-model on all graphs\n",
    "# this helps with properly placing the materials in the validation/test set\n",
    "# as before, you don't need to run this cell\n",
    "# as a trained state_dict is already provided\n",
    "\n",
    "checkpoint_callback = L.callbacks.ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "    monitor=\"valid\",\n",
    "    mode=\"min\",\n",
    "    dirpath=\"ckpts\",\n",
    "    filename=\"{epoch:02d}-{valid:.2f}\",\n",
    ")\n",
    "\n",
    "TrainLoader = torch_geometric.loader.DataLoader(\n",
    "    graphs, batch_size=64, shuffle=True, drop_last=True\n",
    ")\n",
    "\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=200,\n",
    "    check_val_every_n_epoch=20,\n",
    "    precision=\"bf16-mixed\",\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "trainer.fit(model=model_sc, train_dataloaders=TrainLoader, val_dataloaders=ValLoader)\n",
    "checkpoint = torch.load(checkpoint_callback.best_model_path)\n",
    "model_sc.load_state_dict(checkpoint[\"state_dict\"])\n",
    "# torch.save(model_sc.state_dict(), f\"trained_models/dl_sc_all.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sc model\n",
    "state_dict = torch.load(\"trained_models/dl_sc_all.pt\")\n",
    "model_sc.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate latent embeddings and other stuff\n",
    "\n",
    "# As the model is very slightly non-deterministic,\n",
    "# the latents have been pre-generated and the save command is commented out\n",
    "lats = []\n",
    "true_sc = []\n",
    "formula = []\n",
    "model_sc.eval()\n",
    "for graph in graphs:\n",
    "    model_sc.cuda()\n",
    "    graph.cuda()\n",
    "    lat = model_sc.gatnn.latents(graph)\n",
    "    lats.append(lat.cpu().detach().numpy())\n",
    "    true_sc.append(graph.y.cpu().detach().numpy())\n",
    "    formula.append(data_df[data_df[\"mat_id\"] == graph.mat_id][\"formula\"].values[0])\n",
    "lats = np.stack(lats).squeeze(1)\n",
    "true_sc = np.stack(true_sc)\n",
    "# np.save(\"sc_latents.npy\",lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the UMAP\n",
    "import umap\n",
    "\n",
    "lats = np.load(\"sc_latents.npy\")\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=30, min_dist=0.1, random_state=1)\n",
    "reducer.fit(lats)\n",
    "embeds = reducer.embedding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[2 * (3 + 3 / 8), 3 + 3 / 8])\n",
    "plt.scatter(\n",
    "    embeds[:, 0], embeds[:, 1], c=true_sc, s=np.exp(5 * (1 - true_sc)), cmap=\"jet\"\n",
    ")\n",
    "plt.xlabel(\"UMAP component 1\")\n",
    "plt.ylabel(\"UMAP component 2\")\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(\"SC[RPA,IPA]\", rotation=270, labelpad=15)\n",
    "plt.savefig(\"plots/Fig6.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive UMAP plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.palettes import Spectral10\n",
    "from bokeh.models import HoverTool, ColumnDataSource, CategoricalColorMapper\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "try:\n",
    "    from itertools import izip\n",
    "except ImportError:  # Python 3\n",
    "    izip = zip\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "\n",
    "def embeddable_image2(y):\n",
    "    scale = 128\n",
    "    x = np.linspace(0, scale, 2001)\n",
    "    y = 0.9 * scale * (1 - y / np.max(y))\n",
    "    im = Image.new(\"RGB\", (scale, scale), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(im)\n",
    "    draw.line(list(izip(x, y[0])), fill=(31, 119, 180), width=2)\n",
    "    draw.line(list(izip(x, y[1])), fill=(255, 127, 14), width=2)\n",
    "    buffer = BytesIO()\n",
    "    im.save(buffer, format=\"png\")\n",
    "    for_encoding = buffer.getvalue()\n",
    "    return \"data:image/png;base64,\" + base64.b64encode(for_encoding).decode()\n",
    "\n",
    "\n",
    "def load_image(mat_id):\n",
    "    image = Image.open(\"images/\" + mat_id + \".png\")\n",
    "    buffer = BytesIO()\n",
    "    image.thumbnail(size=(128, 128))\n",
    "    image.save(buffer, format=\"png\")\n",
    "    for_encoding = buffer.getvalue()\n",
    "    return \"data:image/png;base64,\" + base64.b64encode(for_encoding).decode()\n",
    "\n",
    "\n",
    "seed = 0\n",
    "\n",
    "\n",
    "# Collect everything into a dataframe for plotting\n",
    "plot_df = pd.DataFrame(embeds, columns=(\"x\", \"y\"))\n",
    "plot_df[\"formula\"] = formula\n",
    "plot_df[\"sc\"] = true_sc\n",
    "\n",
    "sust = []\n",
    "sust_eu = []\n",
    "marker = []\n",
    "size = []\n",
    "spgs = []\n",
    "mat_ids = []\n",
    "gaps = []\n",
    "peak_pos = []\n",
    "peak_hi = []\n",
    "elem_in = []\n",
    "eps_0 = []\n",
    "qw = []\n",
    "for graph in graphs:\n",
    "    entry = data_df[data_df[\"mat_id\"] == graph.mat_id]\n",
    "    marker.append(\"circle\")\n",
    "    size.append(6)\n",
    "    mat_ids.append(graph.mat_id)\n",
    "\n",
    "\n",
    "plot_df[\"markers\"] = marker\n",
    "plot_df[\"sizes\"] = size\n",
    "plot_df[\"ids\"] = mat_ids\n",
    "plot_df[\"crystal\"] = list(map(load_image, mat_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import output_file, save\n",
    "import bokeh\n",
    "from bokeh.palettes import Cividis3, Viridis256\n",
    "from bokeh.transform import linear_cmap\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "datasource = ColumnDataSource(plot_df)\n",
    "\n",
    "colormapper_sc = linear_cmap(\n",
    "    field_name=\"sc\",\n",
    "    palette=bokeh.palettes.Turbo256,\n",
    "    low=min(true_sc),\n",
    "    high=max(true_sc),\n",
    ")\n",
    "\n",
    "# set width and height to fixed values to visualize the map in the notebook\n",
    "# use stretch_both to export the map for viewing in e.g. a browser\n",
    "plot_figure = figure(\n",
    "    title=\"UMAP projection\",\n",
    "    # width=2000,\n",
    "    # height=1000,\n",
    "    sizing_mode=\"stretch_both\",\n",
    "    tools=(\"pan, wheel_zoom, reset, box_zoom\"),\n",
    ")\n",
    "\n",
    "plot_figure.add_tools(\n",
    "    HoverTool(\n",
    "        tooltips=\"\"\"\n",
    "    <figure>\n",
    "        <figcaption style='font-size: 18px; text-align: center;'> \n",
    "            Formula: @formula <br> \n",
    "            ID: @ids \n",
    "        </figcaption>\n",
    "        <img src='@crystal' style='display: block; margin: 5px auto'/>\n",
    "    </figure>\n",
    "\"\"\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Place the name of each material\n",
    "plot_figure.text(\n",
    "    \"x\",\n",
    "    \"y\",\n",
    "    text=\"formula\",\n",
    "    text_font_size=\"20pt\",\n",
    "    text_align=\"center\",\n",
    "    text_baseline=\"middle\",\n",
    "    source=datasource,\n",
    "    x_offset=0,\n",
    "    y_offset=0,\n",
    "    color=colormapper_sc,\n",
    ")\n",
    "\n",
    "show(plot_figure)\n",
    "\n",
    "# Save the image as HTML\n",
    "output_file(\"interactive_plot_sc.html\")\n",
    "save(plot_figure)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
